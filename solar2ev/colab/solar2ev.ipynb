{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"onoU8kbPY8XF"},"outputs":[],"source":["#https://towardsdatascience.com/google-colab-import-and-export-datasets-eccf801e2971\n","\n","#print('my GPU')\n","#!nvidia-smi\n","#print('my CPU')\n","#!cat /proc/cpuinfo\n","\n","import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","\n","# pwd /content\n","# drive.mount('/content/drive', force_remount=True)\n","# gdrive web interface: Mon Drive/DEEP\n","# authorize rigth user to see gdrive content\n","# google drive content: /content/drive/MyDrive\n","# local content, csv dataset: /content/sample_data\n","\n","import tensorflow\n","print('\\ntf version: ', tensorflow.__version__)\n","\n","os.chdir('/content/drive/My Drive/DEEP/solar2ev')\n","print(os.getcwd())\n","!ls\n","\n","\n","\"\"\"\n","# upload file from PC to Colab VM\n","from google.colab import files\n","print ('copy from pc to colab VM')\n","uploaded = files.upload() # form to choose. from PC (can upload multiple file) to colab VM. icon on colab GUI as well\n","print(uploaded) # dict  key = file name, value = file binarie (bytes)\n","print(uploaded.keys()) # iterator, \n","print (list(uploaded.keys())) # could also cast to list\n","for i in uploaded.keys():\n","  print(i) # file name uploaded\n","\"\"\"\n","\n","# Load the TensorBoard notebook extension. Start TensorBoard within the notebook using magics function\n","# log dir is defined in tensorflow call back\n","#https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb\n","\n","%load_ext tensorboard\n","print('delete all files in the TensorBoard directory to only keep last run')\n","!rm -r tensorboard_dir/* # only keep last run\n","%tensorboard --logdir 'tensorboard_dir'\n","\n","%matplotlib inline\n","\n","# needed for pabou helper\n","!pip install tflite_support # to add metadata to TFlite model\n","\n","!pip install keras-tuner # 1.3.0\n","\n","!pip install sdv==0.18.0\n","!pip install kaleido # plotly save figure\n","!pip install calplot\n","\n","\n","# tf 2.11.0 sdv 0.18.0 ok\n","# sdv 1.0.0 available\n","\n","# already there\n","!pip install beautifulsoup4\n","!pip install openpyxl\n","!pip install seaborn\n","!pip install prettytable\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Bd9K2JAfx4Yx"},"source":["run python. need to be in solar2ev "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"hza8FZa6x7Jd"},"outputs":[{"name":"stdout","output_type":"stream","text":["run from:  /content/drive/My Drive/DEEP/solar2ev\n","2023-04-19 05:38:28.973983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","tf:  2.12.0\n","kt:  1.3.5\n","logging to:   ./solar2ev.log\n","importing pabou helper\n","PABOU: import lite_inference\n","importing pabou helper\n","importing meteo scrapping\n","sdv:  0.18.0\n","sdv:  0.18.0\n","importing pabou helper\n","importing pabou helper\n","importing enphase API v4\n","{'app': 'meteo2ev', 'get_data': False, 'train': False, 'bench': False, 'inference': False, 'postmortem': False, 'charge': False, 'features': 'features_input.csv', 'unseen': False, 'retrain': False, 'search': True, 'kerastuner': False, 'vault': False, 'plot': False}\n","current directory:  /content/drive/My Drive/DEEP/solar2ev\n","python executable:  /usr/bin/python3\n","list physical GPU:  []\n","GPU name:  \n","built with CUDA  True\n","panda bin labels. to be converted to onehot [0, 1, 2, 3]\n","sequence length: 90\n","\n","\n","BRUTAL FORCE SEARCH OF VARIOUS FEATURE INPUT, MODEL TYPE and HYPERPARAMETERS\n","result in search_result/result_search_4_19_5_38.csv\n","\n","=== SEARCH 0 . categorical True. 4 bins. 2 heads ===\n","\n","build dataset from df dataframe. features: [['temp', 'production', 'humid', 'direction', 'cos_hour', 'sin_hour'], ['pressure', 'production', 'humid', 'direction', 'cos_hour', 'sin_hour']]. 17496 hours. 729.00 days\n","stride -1, sampling 1, days in seq 4. seqlen 90. labels: True. categorical True\n","list of X(s) (numpy array of hours) used to build dataset, before alignment:  [(17496, 6), (17496, 6)]\n","in days 729.00\n","create dataset with labels, ie ignore last X and first Y, and shift to align\n","X input to create sequences correspond to 725.0 days (last days removed). 17400 hours\n","X input to create sequences correspond to 725.0 days (last days removed). 17400 hours\n","Y is categorical: classification\n","Y labels (17400, 4)\n","create dataset from head X (17400, 6) ie 725.00 days\n","\n","method 3: create dataset from numpy X: (17400, 6)\n","Y: labels (17400, 4)\n","method 3: selection  [18, 20, 21, 22, 23, 0, 1, 2, 3, 4, 6]\n","seq_build_method 3: row 17322. seq_len expected 90, seq_len 78. indicates we are done\n","dataset created:  (TensorSpec(shape=(90, 6), dtype=tf.float64, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None))\n","nb seq: 7937\n","497 batch, 7937 ssquences\n","iter(ds).next() returns  (16, 90, 6) (16, 4)\n","head dataset ready: nb_seq: 7937, seq len 90\n","create dataset from head X (17400, 6) ie 725.00 days\n","\n","method 3: create dataset from numpy X: (17400, 6)\n","Y: labels (17400, 4)\n","method 3: selection  [18, 20, 21, 22, 23, 0, 1, 2, 3, 4, 6]\n","seq_build_method 3: row 17322. seq_len expected 90, seq_len 78. indicates we are done\n","dataset created:  (TensorSpec(shape=(90, 6), dtype=tf.float64, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None))\n","nb seq: 7937\n","497 batch, 7937 ssquences\n","iter(ds).next() returns  (16, 90, 6) (16, 4)\n","head dataset ready: nb_seq: 7937, seq len 90\n","\n","==\u003edataset CREATED. 2 heads. 497 batches, 7937 seq. from X 17400 hours 725 days\n","average batch: 15.97\n","!!! 2 head dataset WITH labels . element spec:  ((TensorSpec(shape=(None, 90, 6), dtype=tf.float64, name=None), TensorSpec(shape=(None, 90, 6), dtype=tf.float64, name=None)), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))\n","head: (16, 90, 6)\n","head: (16, 90, 6)\n","dataset: 496 of 497 incomplete batch  (1, 4)\n","batch misses  15 sequences\n","last batch may be incomplete, would miss 15 seq\n","\n","build solar production histograms\n","2023-04-19 05:38:53.758065: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","2023-04-19 05:38:54.262265: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","histogram of solar productions in number of samples [1980 1979 1998 1980]\n","majority class: index: 2, value: [0. 0. 1. 0.] \n","\n","\u003e\u003e\u003e\u003e\u003e\u003e BEAT THIS for classification: majority class 0.25 percent of total. average 0.25\n","\n","splitting dataset, len in batches 497\n","building size dict\n","total batch 497. train 397, validation 49, test 51\n","\n","build model: use attention ? True\n","\n","build lstm: multi head: True. categorical True\n","2 heads\n","adapting norm 0 on dataset (16, 90, 6) \n","before norm. one batch: std 24, mean 17\n","after norm. one batch: std 1, mean 0\n","adapting norm 1 on dataset (16, 90, 6) \n","before norm. one batch: std 372, mean 183\n","after norm. one batch: std 0, mean 0\n","building lstm stack 0\n","building lstm stack 1\n","\n","TRAINING\n","dataset dict: {'days': 725.0, 'hours': 17400, 'seq': 7937, 'batch': {'total': 497, 'train': 397, 'val': 49, 'test': 51}, 'samples': {'total': 7937, 'train': 6352, 'val': 784, 'test': 816}}\n","metric for early stop and reduce lr:  val_categorical accuracy\n","PABOU: set callbacks list. min delta 0.0001, patience 7\n","callbacks list: [\u003ckeras.callbacks.EarlyStopping object at 0x7f87bca662b0\u003e, \u003ckeras.callbacks.ReduceLROnPlateau object at 0x7f87bca66670\u003e, \u003ckeras.callbacks.TensorBoard object at 0x7f87bca66340\u003e, \u003ckeras.callbacks.ProgbarLogger object at 0x7f87bca66820\u003e, \u003cmodel_solar.CustomCallback_show_val_metrics object at 0x7f87bca668e0\u003e]\n","training dataset: 397 batch, 6352 samples. repeat: 1. method: 3, sampling: 1, stride: -1, days: 4, seq len: 90, 4 bins: [0, 6.9, 15.7, 21.9, 1000000]\n","fit with 397 batches. 80 epochs\n","\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/My Drive/DEEP/solar2ev/solar2ev.py\", line 2414, in \u003cmodule\u003e\n","    brutal_force(search_result_csv)\n","  File \"/content/drive/My Drive/DEEP/solar2ev/solar2ev.py\", line 1614, in brutal_force\n","    history, elapse = train(model, epochs, train_ds, val_ds, categorical, repeat = 1, verbose=0)\n","  File \"/content/drive/My Drive/DEEP/solar2ev/solar2ev.py\", line 526, in train\n","    history = model.fit(\n","  File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1685, in fit\n","    tmp_logs = self.train_function(iterator)\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 894, in __call__\n","    result = self._call(*args, **kwds)\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 926, in _call\n","    return self._no_variable_creation_fn(*args, **kwds)  # pylint: disable=not-callable\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 143, in __call__\n","    return concrete_function._call_flat(\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1757, in _call_flat\n","    return self._build_call_outputs(self._inference_function.call(\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 381, in call\n","    outputs = execute.execute(\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n","    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n","KeyboardInterrupt\n","^C\n"]}],"source":["\n","# make sure we are in the rigth directory\n","os.chdir('/content/drive/My Drive/DEEP/solar2ev')\n","\n","\n","#!rm -r models/*\n","\n","\n","print('run from: ', os.getcwd())\n","\n","\"\"\"\n","-t train\n","-b benchmark\n","-k kerastuner\n","-s search\n","-a solar2ev\n","-v sdv\n","\"\"\"\n","\n","\n","#!python solar2ev.py -v -ameteo2ev \n","#!python solar2ev.py -b -ameteo2ev \n","\n","!python solar2ev.py -s -ameteo2ev \n","#!python solar2ev.py -k -ameteo2ev \n","\n","# commit to gdrive\n","#print ('flush and unmount')\n","#drive.flush_and_unmount()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XGQOVMk0WVsb"},"source":["copy models directory to PC as TAR file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VrlXvF9v-6YD"},"outputs":[],"source":["# copy from gdrive to PC. going thru colab\n","\n","from google.colab import drive\n","from google.colab import files\n","\n","drive.mount('/content/drive') # in case of disconnect\n","os.chdir('/content/drive/My Drive/DEEP/solar2ev')\n"," \n","# create unique name for tar\n","# in /content so in VM instead of /content/drive\n","import uuid\n","unique = str(uuid.uuid4().hex)\n","unique = unique[:5]\n","\n","\n","# cannot download multiples file to PC. so TAR\n","print('==\u003ecreate tar in colab VM from files in gdrive')\n","# brute force search result, and models dir (training, sdv)\n","\n","!tar -cvf /content/colab_models.tar search_result models\n","\n","\n","print('==\u003edownload tar from colab VM to PC')\n","files.download('/content/colab_models.tar')\n","\n","# lands in download directory on PC\n","# untar in models directory on PC. separate file per type (1 or 2), normal or not (1 and 2), concatenate or not (model1), predict velocity (model2)\n"]},{"cell_type":"markdown","metadata":{"id":"PfJZgJRAFozR"},"source":["Google Colab notebooks have an idle timeout of 90 minutes and absolute timeout of 12 hours. This means, if user does not interact with his Google Colab notebook for more than 90 minutes, its instance is automatically terminated. Also, maximum lifetime of a Colab instance is 12 hours.\n","\n","https://stackoverflow.com/questions/57113226/how-to-prevent-google-colab-from-disconnecting\n","\n","restart  !kill -9 -1\n","excecution reinitialiser tous les environment: file donwloaded, pip installed. reset VM and start new 12h \n","\n","restart runtime is only for python kernel, not VM\n","\n","\n","use %cd and not !cd\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","provenance":[{"file_id":"1Pr-n3B8wj9ixs9IX5wlPBOhejefDGfpo","timestamp":1611124843229},{"file_id":"1lznR_twm8_cX8TMqDoyd1L1rqB09GX8a","timestamp":1573990014459},{"file_id":"1wtNJjqkVp5VQOjog__eCwdmDo9OsZaTV","timestamp":1573840134022},{"file_id":"1c1joON1qEc0kTu-2zhDBOH36dLS_O0ot","timestamp":1573836625932},{"file_id":"1yegF1Qs7foBvYYcsJ9LbPGZs8OeQmv2G","timestamp":1573836279806},{"file_id":"1cgN7i7Wm4SbrsTzzYRGKm7f7l5Yinv9v","timestamp":1573834016091}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}